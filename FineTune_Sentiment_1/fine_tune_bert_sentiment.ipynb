{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"mWA9yZmvH21f"},"source":["# Step 1: INstall And Import Python Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13448,"status":"ok","timestamp":1685393005631,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"_Fo0UFZVHUNi","outputId":"b539bd9a-d623-4659-f31c-996723c584e4"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mFailed to start the Kernel. \n","\u001b[1;31mAttributeError: 'KQueueIOLoop' object has no attribute 'asyncio_loop'. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["# Install libraries\n","#https://grabngoinfo.com/transfer-learning-for-text-classification-using-hugging-face-transformers-trainer/"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-ubFOzvpHfbU"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pandas'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Data processing\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Modeling\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"]}],"source":["# Data processing\n","import pandas as pd\n","import numpy as np\n","\n","# Modeling\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, TextClassificationPipeline\n","\n","# Hugging Face Dataset\n","from datasets import Dataset\n","\n","# Model performance evaluation\n","import evaluate"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"K_S1PBvlHvA_"},"source":["# Step 2: Download And Read Data"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2176,"status":"ok","timestamp":1685393016215,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"vywxm_isHymZ","outputId":"6f6dcf89-c72e-4ab6-c2b7-ff4ef14b3f4a"},"outputs":[],"source":["# Mount Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1464,"status":"ok","timestamp":1685393017677,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"DO2X-raHIg0e","outputId":"71342a6c-8674-4188-dd4b-f1f5e9d2f896"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  label\n","0  One of the other reviewers has mentioned that ...      1\n","1  A wonderful little production. <br /><br />The...      1\n","2  I thought this was a wonderful way to spend ti...      1\n","3  Basically there's a family where a little boy ...      0\n","4  Petter Mattei's \"Love in the Time of Money\" is...      1"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# imdb_review = pd.read_csv('/content/drive/MyDrive/data.csv')\n","imdb_review = pd.read_csv('./data.csv')\n","\n","imdb_review = imdb_review.rename(columns={'sentiment': 'label'})\n","\n","imdb_review['label']= imdb_review['label'].map({'positive': 1, 'negative': 0})\n","\n","imdb_review.head()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1685393017677,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"HNHabqg-JxHy","outputId":"c0e5b276-01dc-4c1f-88e6-a6a71cf6d899"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   review  50000 non-null  object\n"," 1   label   50000 non-null  int64 \n","dtypes: int64(1), object(1)\n","memory usage: 781.4+ KB\n"]}],"source":["imdb_review.info()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1685393017677,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"9DTqD4mNJ3r0","outputId":"72b1a782-8db1-4fbe-948f-e6f2f2a52e06"},"outputs":[{"data":{"text/plain":["label\n","1    25000\n","0    25000\n","Name: count, dtype: int64"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Check the label distribution\n","\n","imdb_review['label'].value_counts()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oMZ9WfFgKAEj"},"source":["#Step 3:  Train Test  Split"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BFF4lWN0H1Q-"},"source":[]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1685393017678,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"t1wn36PWKKx-","outputId":"d815941e-bd79-48a0-976a-51685132fa07"},"outputs":[{"name":"stdout","output_type":"stream","text":["The training dataset has 40000 records.\n","The testing dataset has 10000 records.\n"]}],"source":["# Training dataset\n","train_data = imdb_review.sample(frac=0.8, random_state=42)\n","\n","# Testing dataset\n","test_data = imdb_review.drop(train_data.index)\n","\n","# Check the number of records in training and testing dataset.\n","print(f'The training dataset has {len(train_data)} records.')\n","print(f'The testing dataset has {len(test_data)} records.')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"brGT8jzSKZ-G"},"source":["# Step 4: Convert Pandas Dataframe To Hugging Face Dataset\n","\n","\n","Hugging Face Dataset objects are memory mapped on drive so they are not limited by RAM memory which is very helpful for processing large datasets"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"UuSCMa96Knmx"},"outputs":[],"source":["# Convert pyhton dataframe to Hugging Face arrow dataset\n","hg_train_data = Dataset.from_pandas(train_data)\n","hg_test_data = Dataset.from_pandas(test_data)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1685393017679,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"VU7iXaCbK0MO","outputId":"ae07fabc-9d80-42eb-bd00-836f8126a36c"},"outputs":[{"name":"stdout","output_type":"stream","text":["The length of hg_train_data is 40000.\n","\n"]},{"data":{"text/plain":["{'review': \"I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10\",\n"," 'label': 1,\n"," '__index_level_0__': 33553}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Length of the Dataset\n","print(f'The length of hg_train_data is {len(hg_train_data)}.\\n')\n","\n","# Check one review\n","hg_train_data[0]"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_tLB64tiK-k0"},"source":["# Step 5: Tokenize Text\n","\n","A tokenizer converts text into numbers to use as the input of the NLP (Natural Language Processing) models."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1685393017679,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"uKxYfacpLHAU","outputId":"53bc7864-bc22-42a9-cd47-6eb9c47fda82"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading (…)okenizer_config.json: 100%|██████████| 29.0/29.0 [00:00<00:00, 9.62kB/s]\n","Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 304kB/s]\n","Downloading (…)solve/main/vocab.txt: 100%|██████████| 213k/213k [00:00<00:00, 1.09MB/s]\n","Downloading (…)/main/tokenizer.json: 100%|██████████| 436k/436k [00:00<00:00, 4.60MB/s]\n"]},{"data":{"text/plain":["BertTokenizerFast(name_or_path='bert-base-cased', vocab_size=28996, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["# Tokenizer from a pretrained model\n","tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n","\n","# Take a look at the tokenizer\n","tokenizer"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1685393017680,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"l5zaoSP3LVb0","outputId":"ecdf0c6e-8ee2-4e4c-f3f0-b5570a944e48"},"outputs":[{"name":"stdout","output_type":"stream","text":["The unknown token is [UNK] and the ID for the unkown token is 100.\n","The seperator token is [SEP] and the ID for the seperator token is 102.\n","The pad token is [PAD] and the ID for the pad token is 0.\n","The sentence level classification token is [CLS] and the ID for the classification token is 101.\n","The mask token is [MASK] and the ID for the mask token is 103.\n"]}],"source":["# Mapping between special tokens and their IDs.\n","print(f'The unknown token is {tokenizer.unk_token} and the ID for the unkown token is {tokenizer.unk_token_id}.')\n","print(f'The seperator token is {tokenizer.sep_token} and the ID for the seperator token is {tokenizer.sep_token_id}.')\n","print(f'The pad token is {tokenizer.pad_token} and the ID for the pad token is {tokenizer.pad_token_id}.')\n","print(f'The sentence level classification token is {tokenizer.cls_token} and the ID for the classification token is {tokenizer.cls_token_id}.')\n","print(f'The mask token is {tokenizer.mask_token} and the ID for the mask token is {tokenizer.mask_token_id}.')"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["cd40a390facf40c4a0607545a2122d97","fbd9d5c4d1234640b0148fe67fb90879","40eee859b61f464c8b9266e6fadab59c","7242527ea3c14d65a5f85ece3634e794","ff02629383c04265bce880e28f9ab6cd","56282ffa948743abb64b0f57ca26a219","d22b37ebd4ea463ca3bfae1938e1a84c","8717090406b74bb1898c85be1093831d","912c03bb30d24095a2ee9829ac721e01","d567a97781734c74bab1f9cb4c659534","3b80295a3ab84f4b8ab4147bb1098a93","224a06a96aad47b5bd2cd0ce765f6ed1","2c216fdee1a74cfb8df85ab6c6b0ff21","ad2002929c6a4b64bd4ac1f4d3abbdea","c795087451674befac4a54bd96597bba","bf35d0031b2a40f4a262518050db3ec1","9bd00551de1746c6907353b1670d5b5b","0091f769e3614b68aa4dd457ff3c85bb","c489d8ded2df44d8884808d4587931d7","be211514ca3c49a18c64294c6d98ab75","27225003f80e4563affa0e0413b523c5","99345c0c921f44c3b14e0e7990957564"]},"executionInfo":{"elapsed":77651,"status":"ok","timestamp":1685393095319,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"qwn1BAP4LcZJ","outputId":"82202a1e-9b2e-49c4-afb7-dd36cb009250"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                   \r"]}],"source":["# Function to tokenize data\n","\n","def tokenize_dataset(data):\n","    return tokenizer(data['review'], max_length=32, truncation=True, padding=\"max_length\")\n","\n","# Tokenize the dataset\n","dataset_train = hg_train_data.map(tokenize_dataset)\n","dataset_test = hg_test_data.map(tokenize_dataset)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685393095320,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"Sm1cP2InMTNf","outputId":"39342405-2628-432c-a527-aa682803f6c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['review', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 40000\n","})\n","Dataset({\n","    features: ['review', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 10000\n","})\n","{'review': \"I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10\", 'label': 1, '__index_level_0__': 33553, 'input_ids': [101, 146, 1541, 3851, 1142, 22596, 7609, 1496, 1106, 1103, 1440, 1104, 1103, 8176, 117, 1103, 15800, 1105, 1198, 1103, 1440, 2905, 1108, 5426, 1106, 1143, 1111, 1199, 2255, 119, 10756, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"]}],"source":["# Take a look at the data\n","print(dataset_train)\n","print(dataset_test)\n","print(dataset_train[0])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ngphxk-YMuQd"},"source":["# Step 6: Load Pretrained Model\n","\n","\n","\n","\n","- AutoModelForSequenceClassification loads the BERT model without the sequence classification head.\n","- The method from_pretrained() loads the weights from the pretrained model into the new model, so the weights in the new model are not randomly initialized. Note that the new weights for the new sequence classification head are going to be randomly initialized.\n","- bert-base-cased is the name of the pretrained model. We can change it to a different model based on the nature of the project.\n","- num_labels indicates the number of classes. Our dataset has two classes, positive and negative, so num_labels=2.\n"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1563,"status":"ok","timestamp":1685393096879,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"iW8BknDmM-Qq","outputId":"85e026ed-0c78-48e7-9d9f-bcd4211b4dce"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading pytorch_model.bin: 100%|██████████| 436M/436M [00:16<00:00, 26.8MB/s] \n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load model\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jj4JsOAtOBIE"},"source":["# Step 7 Set Training Argument\n","\n","Hugging Face has 96 parameters for TrainingArguments, which provides a lot of flexibility in fine-tuning the transfer learning model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qvOA4BxOl9X"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"fmzXIXn9OD8k"},"outputs":[],"source":["# Set up training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./sentiment_transfer_learning_transformer/\",          \n","    logging_dir='./sentiment_transfer_learning_transformer/logs',            \n","    logging_strategy='epoch',\n","    logging_steps=100,    \n","    num_train_epochs=2,              \n","    per_device_train_batch_size=4,  \n","    per_device_eval_batch_size=4,  \n","    learning_rate=5e-6,\n","    seed=42,\n","    save_strategy='epoch',\n","    save_steps=100,\n","    evaluation_strategy='epoch',\n","    eval_steps=100,\n","    load_best_model_at_end=True\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"u4OeRQ2dQlXi"},"source":["Step 8: Set Evaluation Metrics\n","\n","In step 8, we will set the evaluation metric because Hugging Face Trainer does not evaluate the model performance automatically during the training process."]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5505,"status":"ok","timestamp":1685393170448,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"ok8MBGAIQr3V","outputId":"000b92cc-ce34-4d6b-f4d1-eab182725cbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 161 evaluation models in Hugging Face.\n","\n"]},{"data":{"text/plain":["['lvwerra/test',\n"," 'precision',\n"," 'code_eval',\n"," 'roc_auc',\n"," 'cuad',\n"," 'xnli',\n"," 'rouge',\n"," 'pearsonr',\n"," 'mse',\n"," 'super_glue',\n"," 'comet',\n"," 'cer',\n"," 'sacrebleu',\n"," 'mahalanobis',\n"," 'wer',\n"," 'competition_math',\n"," 'f1',\n"," 'recall',\n"," 'coval',\n"," 'mauve',\n"," 'xtreme_s',\n"," 'bleurt',\n"," 'ter',\n"," 'accuracy',\n"," 'exact_match',\n"," 'indic_glue',\n"," 'spearmanr',\n"," 'mae',\n"," 'squad',\n"," 'chrf',\n"," 'glue',\n"," 'perplexity',\n"," 'mean_iou',\n"," 'squad_v2',\n"," 'meteor',\n"," 'bleu',\n"," 'wiki_split',\n"," 'sari',\n"," 'frugalscore',\n"," 'google_bleu',\n"," 'bertscore',\n"," 'matthews_correlation',\n"," 'seqeval',\n"," 'trec_eval',\n"," 'rl_reliability',\n"," 'jordyvl/ece',\n"," 'angelina-wang/directional_bias_amplification',\n"," 'cpllab/syntaxgym',\n"," 'lvwerra/bary_score',\n"," 'kaggle/amex',\n"," 'kaggle/ai4code',\n"," 'hack/test_metric',\n"," 'yzha/ctc_eval',\n"," 'codeparrot/apps_metric',\n"," 'mfumanelli/geometric_mean',\n"," 'daiyizheng/valid',\n"," 'poseval',\n"," 'erntkn/dice_coefficient',\n"," 'mgfrantz/roc_auc_macro',\n"," 'Vlasta/pr_auc',\n"," 'gorkaartola/metric_for_tp_fp_samples',\n"," 'idsedykh/metric',\n"," 'idsedykh/codebleu2',\n"," 'idsedykh/codebleu',\n"," 'idsedykh/megaglue',\n"," 'cakiki/ndcg',\n"," 'brier_score',\n"," 'Vertaix/vendiscore',\n"," 'GMFTBY/dailydialogevaluate',\n"," 'GMFTBY/dailydialog_evaluate',\n"," 'jzm-mailchimp/joshs_second_test_metric',\n"," 'ola13/precision_at_k',\n"," 'yulong-me/yl_metric',\n"," 'abidlabs/mean_iou',\n"," 'abidlabs/mean_iou2',\n"," 'KevinSpaghetti/accuracyk',\n"," 'NimaBoscarino/weat',\n"," 'ronaldahmed/nwentfaithfulness',\n"," 'Viona/infolm',\n"," 'kyokote/my_metric2',\n"," 'kashif/mape',\n"," 'Ochiroo/rouge_mn',\n"," 'giulio98/code_eval_outputs',\n"," 'leslyarun/fbeta_score',\n"," 'giulio98/codebleu',\n"," 'anz2/iliauniiccocrevaluation',\n"," 'zbeloki/m2',\n"," 'xu1998hz/sescore',\n"," 'mase',\n"," 'mape',\n"," 'smape',\n"," 'dvitel/codebleu',\n"," 'NCSOFT/harim_plus',\n"," 'JP-SystemsX/nDCG',\n"," 'sportlosos/sescore',\n"," 'Drunper/metrica_tesi',\n"," 'jpxkqx/peak_signal_to_noise_ratio',\n"," 'jpxkqx/signal_to_reconstrution_error',\n"," 'hpi-dhc/FairEval',\n"," 'nist_mt',\n"," 'lvwerra/accuracy_score',\n"," 'character',\n"," 'charcut_mt',\n"," 'ybelkada/cocoevaluate',\n"," 'harshhpareek/bertscore',\n"," 'posicube/mean_reciprocal_rank',\n"," 'bstrai/classification_report',\n"," 'omidf/squad_precision_recall',\n"," 'Josh98/nl2bash_m',\n"," 'BucketHeadP65/confusion_matrix',\n"," 'BucketHeadP65/roc_curve',\n"," 'yonting/average_precision_score',\n"," 'transZ/test_parascore',\n"," 'transZ/sbert_cosine',\n"," 'hynky/sklearn_proxy',\n"," 'xu1998hz/sescore_english_mt',\n"," 'xu1998hz/sescore_german_mt',\n"," 'xu1998hz/sescore_english_coco',\n"," 'xu1998hz/sescore_english_webnlg',\n"," 'unnati/kendall_tau_distance',\n"," 'r_squared',\n"," 'Viona/fuzzy_reordering',\n"," 'Viona/kendall_tau',\n"," 'lhy/hamming_loss',\n"," 'lhy/ranking_loss',\n"," 'Muennighoff/code_eval',\n"," 'yuyijiong/quad_match_score',\n"," 'Splend1dchan/cosine_similarity',\n"," 'Yeshwant123/mcc',\n"," 'transformersegmentation/segmentation_scores',\n"," 'sma2023/wil',\n"," 'chanelcolgate/average_precision',\n"," 'ckb/unigram',\n"," 'Felipehonorato/eer',\n"," 'manueldeprada/beer',\n"," 'tialaeMceryu/unigram',\n"," 'shunzh/apps_metric',\n"," 'He-Xingwei/sari_metric',\n"," 'langdonholmes/cohen_weighted_kappa',\n"," 'fschlatt/ner_eval',\n"," 'hyperml/balanced_accuracy',\n"," 'brian920128/doc_retrieve_metrics',\n"," 'mcnemar',\n"," 'exact_match',\n"," 'wilcoxon',\n"," 'ncoop57/levenshtein_distance',\n"," 'kaleidophon/almost_stochastic_order',\n"," 'word_length',\n"," 'lvwerra/element_count',\n"," 'word_count',\n"," 'text_duplicates',\n"," 'perplexity',\n"," 'label_distribution',\n"," 'toxicity',\n"," 'prb977/cooccurrence_count',\n"," 'regard',\n"," 'honest',\n"," 'NimaBoscarino/pseudo_perplexity',\n"," 'ybelkada/toxicity',\n"," 'ronaldahmed/ccl_win',\n"," 'meg/perplexity']"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# Number of evaluation modules\n","print(f'There are {len(evaluate.list_evaluation_modules())} evaluation models in Hugging Face.\\n')\n","\n","# List all evaluation metrics\n","evaluate.list_evaluation_modules()"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"5159emxxQ0Uk"},"outputs":[],"source":["# Function to compute the metric\n","def compute_metrics(eval_pred):\n","    metric = evaluate.load(\"accuracy\")\n","    logits, labels = eval_pred\n","    # probabilities = tf.nn.softmax(logits)\n","    predictions = np.argmax(logits, axis=1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"oLD-RzsaQ7tf"},"source":["# Step9: Train Model Using Transformer Trainer"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"44UwDA_gQ_0E"},"outputs":[],"source":["# Train the model\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset_train,\n","    eval_dataset=dataset_test,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280,"referenced_widgets":["cedc5a6cbb3143abbf3c631c0bb41b53","add2fe5c976c4c4eb0b9e4161659936c","4b454ebf83fb4995835a5240c0bb03c8","904b3b7fb3a94686b0916bb2bf327572","7ecdf33d29144fdc8fd563fba5fe48e0","d1332a20101c4653945c7adf2c005539","b5276b7d47e64303a2ee0a7881e07548","56928d3b4fb4476f9038bbae41c21b40","d682f826fb9847f38f902d642d484768","3034b78a8d0c436194f65fd4ed11239d","c811c60a39f24e6d8edcf567061016f6"]},"executionInfo":{"elapsed":1541861,"status":"ok","timestamp":1685394810461,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"fylQbDf1REcE","outputId":"ffee88b1-1ad7-46de-9db3-5d52bdc0e321"},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe kernel failed to start due to the missing module 'prompt_toolkit.formatted_text'. Consider installing this module.\n","\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."]}],"source":["trainer.train()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"iqMuOOGwXXHV"},"source":["# Step 11: Evaluate Model Performance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145},"executionInfo":{"elapsed":40117,"status":"ok","timestamp":1685394869577,"user":{"displayName":"johannes widera","userId":"17847477834710513842"},"user_tz":-120},"id":"2Dl7ZKbtXBpJ","outputId":"ddd3743a-c9b6-472a-cf14-86190c6e979f"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2500/2500 00:38]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.5471986532211304,\n"," 'eval_accuracy': 0.76,\n"," 'eval_runtime': 39.6333,\n"," 'eval_samples_per_second': 252.313,\n"," 'eval_steps_per_second': 63.078,\n"," 'epoch': 2.0}"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Trainer evaluate\n","trainer.evaluate(dataset_test)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2i5RbHtKXcar"},"source":["# Step 12: Save and Load The Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6y8DXHMXfW4"},"outputs":[],"source":["# Save tokenizer\n","tokenizer.save_pretrained('./sentiment_transfer_learning_transformer/')\n","\n","# Save model\n","trainer.save_model('./sentiment_transfer_learning_transformer/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9RwtH7a8Xu01"},"outputs":[],"source":["# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"./sentiment_transfer_learning_transformer/\")\n","\n","# Load model\n","loaded_model = AutoModelForSequenceClassification.from_pretrained('./sentiment_transfer_learning_transformer/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ep4lQXQmYVNG","outputId":"4d3452fa-9ef5-4cbb-9a80-4f6912f74186"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: sentiment_transfer_learning_transformer/ (stored 0%)\n","  adding: sentiment_transfer_learning_transformer/special_tokens_map.json (deflated 42%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/ (stored 0%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/rng_state.pth (deflated 28%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/config.json (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/optimizer.pt (deflated 17%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/training_args.bin (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/pytorch_model.bin (deflated 7%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/trainer_state.json (deflated 63%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-20000/scheduler.pt (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/config.json (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/tokenizer_config.json (deflated 42%)\n","  adding: sentiment_transfer_learning_transformer/vocab.txt (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/logs/ (stored 0%)\n","  adding: sentiment_transfer_learning_transformer/logs/events.out.tfevents.1685393268.1288e43d8f32.3631.0 (deflated 58%)\n","  adding: sentiment_transfer_learning_transformer/logs/events.out.tfevents.1685394868.1288e43d8f32.3631.2 (deflated 27%)\n","  adding: sentiment_transfer_learning_transformer/logs/1685393268.3998823/ (stored 0%)\n","  adding: sentiment_transfer_learning_transformer/logs/1685393268.3998823/events.out.tfevents.1685393268.1288e43d8f32.3631.1 (deflated 63%)\n","  adding: sentiment_transfer_learning_transformer/training_args.bin (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/tokenizer.json (deflated 70%)\n","  adding: sentiment_transfer_learning_transformer/pytorch_model.bin (deflated 7%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-10000/ (stored 0%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-10000/rng_state.pth (deflated 28%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-10000/config.json (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-10000/optimizer.pt (deflated 17%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-10000/training_args.bin (deflated 49%)\n","  adding: sentiment_transfer_learning_transformer/checkpoint-10000/pytorch_model.bin"]}],"source":["# !zip -r sentiment_transfer_learning_transformer.zip sentiment_transfer_learning_transformer/ "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2W1X5LfW2xcv"},"source":["# Step 13: Analysis with SHAP"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNgde5rl0nY5ZaV8lVewG/8","collapsed_sections":["K_S1PBvlHvA_","oMZ9WfFgKAEj","brGT8jzSKZ-G"],"gpuType":"T4","mount_file_id":"1aEFThcT0gCz3UU1ZEjgvKkAEZ-bO1E_Y","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0091f769e3614b68aa4dd457ff3c85bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"224a06a96aad47b5bd2cd0ce765f6ed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c216fdee1a74cfb8df85ab6c6b0ff21","IPY_MODEL_ad2002929c6a4b64bd4ac1f4d3abbdea","IPY_MODEL_c795087451674befac4a54bd96597bba"],"layout":"IPY_MODEL_bf35d0031b2a40f4a262518050db3ec1"}},"27225003f80e4563affa0e0413b523c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c216fdee1a74cfb8df85ab6c6b0ff21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bd00551de1746c6907353b1670d5b5b","placeholder":"​","style":"IPY_MODEL_0091f769e3614b68aa4dd457ff3c85bb","value":"Map: 100%"}},"3034b78a8d0c436194f65fd4ed11239d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b80295a3ab84f4b8ab4147bb1098a93":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40eee859b61f464c8b9266e6fadab59c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8717090406b74bb1898c85be1093831d","max":40000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_912c03bb30d24095a2ee9829ac721e01","value":40000}},"4b454ebf83fb4995835a5240c0bb03c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_56928d3b4fb4476f9038bbae41c21b40","max":4203,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d682f826fb9847f38f902d642d484768","value":4203}},"56282ffa948743abb64b0f57ca26a219":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56928d3b4fb4476f9038bbae41c21b40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7242527ea3c14d65a5f85ece3634e794":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d567a97781734c74bab1f9cb4c659534","placeholder":"​","style":"IPY_MODEL_3b80295a3ab84f4b8ab4147bb1098a93","value":" 39935/40000 [01:03&lt;00:00, 821.03 examples/s]"}},"7ecdf33d29144fdc8fd563fba5fe48e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8717090406b74bb1898c85be1093831d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"904b3b7fb3a94686b0916bb2bf327572":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3034b78a8d0c436194f65fd4ed11239d","placeholder":"​","style":"IPY_MODEL_c811c60a39f24e6d8edcf567061016f6","value":" 4.20k/4.20k [00:00&lt;00:00, 254kB/s]"}},"912c03bb30d24095a2ee9829ac721e01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99345c0c921f44c3b14e0e7990957564":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9bd00551de1746c6907353b1670d5b5b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad2002929c6a4b64bd4ac1f4d3abbdea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c489d8ded2df44d8884808d4587931d7","max":10000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be211514ca3c49a18c64294c6d98ab75","value":10000}},"add2fe5c976c4c4eb0b9e4161659936c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1332a20101c4653945c7adf2c005539","placeholder":"​","style":"IPY_MODEL_b5276b7d47e64303a2ee0a7881e07548","value":"Downloading builder script: 100%"}},"b5276b7d47e64303a2ee0a7881e07548":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be211514ca3c49a18c64294c6d98ab75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf35d0031b2a40f4a262518050db3ec1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"c489d8ded2df44d8884808d4587931d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c795087451674befac4a54bd96597bba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27225003f80e4563affa0e0413b523c5","placeholder":"​","style":"IPY_MODEL_99345c0c921f44c3b14e0e7990957564","value":" 9998/10000 [00:13&lt;00:00, 852.99 examples/s]"}},"c811c60a39f24e6d8edcf567061016f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd40a390facf40c4a0607545a2122d97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbd9d5c4d1234640b0148fe67fb90879","IPY_MODEL_40eee859b61f464c8b9266e6fadab59c","IPY_MODEL_7242527ea3c14d65a5f85ece3634e794"],"layout":"IPY_MODEL_ff02629383c04265bce880e28f9ab6cd"}},"cedc5a6cbb3143abbf3c631c0bb41b53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_add2fe5c976c4c4eb0b9e4161659936c","IPY_MODEL_4b454ebf83fb4995835a5240c0bb03c8","IPY_MODEL_904b3b7fb3a94686b0916bb2bf327572"],"layout":"IPY_MODEL_7ecdf33d29144fdc8fd563fba5fe48e0"}},"d1332a20101c4653945c7adf2c005539":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d22b37ebd4ea463ca3bfae1938e1a84c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d567a97781734c74bab1f9cb4c659534":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d682f826fb9847f38f902d642d484768":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbd9d5c4d1234640b0148fe67fb90879":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56282ffa948743abb64b0f57ca26a219","placeholder":"​","style":"IPY_MODEL_d22b37ebd4ea463ca3bfae1938e1a84c","value":"Map: 100%"}},"ff02629383c04265bce880e28f9ab6cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}}}}},"nbformat":4,"nbformat_minor":0}
